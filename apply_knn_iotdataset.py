# -*- coding: utf-8 -*-
"""Apply_KNN_IOTdataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KU9dyYGFn9CVcUsg6JkwPWvJ7eS7fopu
"""

import pandas as pd

# Load the parquet file
file_path = '/content/drive/MyDrive/AI_LAB/Assignment 1/NF-ToN-IoT-V2.parquet'
df = pd.read_parquet(file_path)

# Show the first few rows
print(df.head())

print("Shape:", df.shape)
print("Columns:", df.columns)
print("Data types:\n", df.dtypes)
print("Missing values:\n", df.isnull().sum())

import pandas as pd

file_path = '/content/drive/MyDrive/AI_LAB/Assignment 1/NF-ToN-IoT-V2.parquet'
df = pd.read_parquet(file_path)

print(df.head())

"""**2. Understand your dataset**"""

print(df.columns)  # check columns
print(df.dtypes)   # data types
print(df.isnull().sum())  # missing values count

"""**3. Preprocessing before KNN**



"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer

# Replace 'target' with the actual name of your target column
target_col = 'target'

# Separate features and target
X = df.drop(columns=[target_col])
y = df[target_col]

# Handling missing values (mean imputation for numeric)
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X)

# Feature scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_imputed)

# Train-test split (e.g., 80-20)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

"""**4. Train and test KNN**"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
import pandas as pd
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Load the parquet file
file_path = '/content/drive/MyDrive/AI_LAB/Assignment 1/NF-ToN-IoT-V2.parquet'
df = pd.read_parquet(file_path)

# Replace 'target' with the actual name of your target column
target_col = 'Label'

# Separate features and target
X = df.drop(columns=[target_col])
y = df[target_col]

# Handling missing values (mean imputation for numeric)
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X)

# Feature scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_imputed)

# Train-test split (e.g., 80-20)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Initialize KNN, you can choose k neighbors (start with k=5)
knn = KNeighborsClassifier(n_neighbors=5)

# Train
knn.fit(X_train, y_train)

# Predict
y_pred = knn.predict(X_test)

# Evaluate
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))